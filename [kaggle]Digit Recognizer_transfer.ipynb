{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[kaggle]Digit Recognizer_transfer.ipynb","provenance":[{"file_id":"1IzPbxNFQmmSYk9s14L4YjBfUgACn9mW2","timestamp":1596897349959},{"file_id":"1G7NKeneJNyRtcRxLVbbF9jYtRyuTOa-R","timestamp":1592749700622},{"file_id":"https://github.com/satyajitghana/TSAI-DeepVision-EVA4.0/blob/master/Utils/Colab_25GBRAM_GPU.ipynb","timestamp":1592043804148}],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"LUzBsaxKpJ-4"},"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import seaborn as sns\n","%matplotlib inline\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","import itertools\n","\n","from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n","from keras.models import Sequential, Model, load_model\n","from keras.layers import Input, Dense, Dropout, Flatten, Activation, Conv2D, MaxPooling2D, AveragePooling2D, BatchNormalization, ZeroPadding2D, add\n","from keras.optimizers import RMSprop\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","from keras.applications.vgg16 import VGG16\n","from keras import backend as k\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rT_PtZGpUAr"},"source":["train = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/kaggle/Digit Recognizer/data/train.csv\")\n","test = pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/kaggle/Digit Recognizer/data/test.csv\")\n","X_train = (train.iloc[:,1:].values).astype('float32') # all pixel values\n","y_train = train.iloc[:,0].values.astype(int) # only labels i.e targets digits\n","X_test = test.values.astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R_tBvE-7pd0R"},"source":["k.clear_session()\n","X_train = X_train.reshape(-1, 28, 28,1)\n","X_test = X_test.reshape(-1, 28, 28,1)\n","X_train=X_train[:12000]\n","X_test=X_test[:12000]\n","y_train=y_train[:12000]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGi9RNWqpfvN"},"source":["#轉成VGG16需要的格式，要RGB通道(資料太多會爆RAM)\n","ishape = 224\n","X_train = [cv2.cvtColor(cv2.resize(i,(ishape,ishape)), cv2.COLOR_GRAY2BGR) for i in X_train]\n","X_train = np.array(X_train)\n","# 增加維度(沒用到)\n","# X_train = np.concatenate([arr[np.newaxis] for arr in X_train]).astype('float32')\n"," \n","X_test  = [cv2.cvtColor(cv2.resize(i,(ishape,ishape)), cv2.COLOR_GRAY2BGR) for i in X_test]\n","X_test = np.array(X_test)\n","# X_test  = np.concatenate([arr[np.newaxis] for arr in X_test] ).astype('float32')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HzTtjRcdyT6G"},"source":["X_train = X_train/255\n","X_test = X_test/255\n","\n","y_train = to_categorical(y_train, num_classes = 10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3NbfG7I0jih"},"source":["random_seed = 42\n","# Split the train and the validation set for the fitting\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.15, random_state=random_seed)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9bi3qlnfyuCu"},"source":["k.clear_session()\n","model_vgg = VGG16(include_top=False, weights='imagenet', input_shape=(ishape, ishape, 3))\n","for layers in model_vgg.layers:\n","    layers.trainable = False\n"," \n","model = Flatten()(model_vgg.output)\n","output = Dense(10, activation='softmax')(model)\n","model_vgg_pretrain = Model(inputs=model_vgg.input, outputs=output, name='vgg16_pretrain')\n","# model_vgg_mnist_pretrain.summary()\n","model_vgg_pretrain.compile(optimizer='adam', loss='categorical_crossentropy',\n","                                 metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZejpCyERzwWo"},"source":["# With data augmentation to prevent overfitting\n","        featurewise_center=False,  # set input mean to 0 over the dataset\n","        samplewise_center=False,  # set each sample mean to 0\n","        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n","        samplewise_std_normalization=False,  # divide each input by its std\n","        zca_whitening=False,  # apply ZCA whitening\n","        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n","        zoom_range = 0.1, # Randomly zoom image \n","        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n","        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n","        horizontal_flip=False,  # randomly flip images\n","        vertical_flip=False,  # randomly flip images\n","        data_format='channels_last')  \n","\n","\n","datagen.fit(X_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY9TV5IQ3JdW"},"source":["#學習率下降\n","reduce_lr = ReduceLROnPlateau(factor=0.5, \n","                              min_lr=1e-12, \n","                              monitor='val_accuracy', \n","                              patience=2, \n","                              verbose=1)\n","#儲存最佳模型\n","model_ckpt = ModelCheckpoint(filepath=\"/content/drive/My Drive/Colab Notebooks/kaggle/Digit Recognizer/model/best_trans_model.h5\", \n","                             monitor=\"val_accuracy\", \n","                             save_best_only=True)\n","#提早終止\n","earlystop = EarlyStopping(monitor=\"val_accuracy\", \n","                          patience=10, \n","                          verbose=1\n","                          )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P8TLnHSEz5-v","executionInfo":{"status":"ok","timestamp":1601603763567,"user_tz":-480,"elapsed":2596367,"user":{"displayName":"H24991237李軒慶","photoUrl":"","userId":"13081121285540079652"}},"outputId":"b3320546-b069-41e5-a9ce-3d97ea09674f","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# Fit the model\n","history = model_vgg_pretrain.fit(datagen.flow(X_train,y_train, batch_size=128),\n","                    # steps_per_epoch=完成一次epoch需要跑多少個batch\n","                    steps_per_epoch=X_train.shape[0]//128,\n","                    validation_data=(X_val,y_val),\n","                    epochs = 200,\n","                    callbacks=[earlystop, model_ckpt,reduce_lr],\n","                    verbose = 1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/200\n","79/79 [==============================] - 95s 1s/step - loss: 0.5099 - accuracy: 0.8576 - val_loss: 0.1055 - val_accuracy: 0.9756\n","Epoch 2/200\n","79/79 [==============================] - 93s 1s/step - loss: 0.1204 - accuracy: 0.9701 - val_loss: 0.0747 - val_accuracy: 0.9783\n","Epoch 3/200\n","79/79 [==============================] - 92s 1s/step - loss: 0.0927 - accuracy: 0.9759 - val_loss: 0.0585 - val_accuracy: 0.9828\n","Epoch 4/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0703 - accuracy: 0.9828 - val_loss: 0.0538 - val_accuracy: 0.9817\n","Epoch 5/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0602 - accuracy: 0.9847\n","Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0602 - accuracy: 0.9847 - val_loss: 0.0536 - val_accuracy: 0.9811\n","Epoch 6/200\n","79/79 [==============================] - 92s 1s/step - loss: 0.0483 - accuracy: 0.9887 - val_loss: 0.0489 - val_accuracy: 0.9839\n","Epoch 7/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0427 - accuracy: 0.9892 - val_loss: 0.0496 - val_accuracy: 0.9828\n","Epoch 8/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9915\n","Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0418 - accuracy: 0.9915 - val_loss: 0.0533 - val_accuracy: 0.9822\n","Epoch 9/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0370 - accuracy: 0.9914 - val_loss: 0.0453 - val_accuracy: 0.9833\n","Epoch 10/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9940\n","Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0330 - accuracy: 0.9940 - val_loss: 0.0466 - val_accuracy: 0.9839\n","Epoch 11/200\n","79/79 [==============================] - 90s 1s/step - loss: 0.0339 - accuracy: 0.9916 - val_loss: 0.0467 - val_accuracy: 0.9833\n","Epoch 12/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9939\n","Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0322 - accuracy: 0.9939 - val_loss: 0.0479 - val_accuracy: 0.9833\n","Epoch 13/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0320 - accuracy: 0.9927 - val_loss: 0.0449 - val_accuracy: 0.9844\n","Epoch 14/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0305 - accuracy: 0.9941 - val_loss: 0.0439 - val_accuracy: 0.9850\n","Epoch 15/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0323 - accuracy: 0.9927 - val_loss: 0.0449 - val_accuracy: 0.9844\n","Epoch 16/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9944\n","Epoch 00016: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0279 - accuracy: 0.9944 - val_loss: 0.0432 - val_accuracy: 0.9850\n","Epoch 17/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0295 - accuracy: 0.9938 - val_loss: 0.0441 - val_accuracy: 0.9844\n","Epoch 18/200\n","79/79 [==============================] - 92s 1s/step - loss: 0.0299 - accuracy: 0.9943 - val_loss: 0.0441 - val_accuracy: 0.9856\n","Epoch 19/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0303 - accuracy: 0.9936 - val_loss: 0.0437 - val_accuracy: 0.9856\n","Epoch 20/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0279 - accuracy: 0.9945\n","Epoch 00020: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n","79/79 [==============================] - 90s 1s/step - loss: 0.0279 - accuracy: 0.9945 - val_loss: 0.0432 - val_accuracy: 0.9856\n","Epoch 21/200\n","79/79 [==============================] - 90s 1s/step - loss: 0.0288 - accuracy: 0.9934 - val_loss: 0.0432 - val_accuracy: 0.9856\n","Epoch 22/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0297 - accuracy: 0.9947\n","Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n","79/79 [==============================] - 93s 1s/step - loss: 0.0297 - accuracy: 0.9947 - val_loss: 0.0433 - val_accuracy: 0.9856\n","Epoch 23/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0278 - accuracy: 0.9948 - val_loss: 0.0432 - val_accuracy: 0.9850\n","Epoch 24/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9953\n","Epoch 00024: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0276 - accuracy: 0.9953 - val_loss: 0.0432 - val_accuracy: 0.9856\n","Epoch 25/200\n","79/79 [==============================] - 91s 1s/step - loss: 0.0280 - accuracy: 0.9945 - val_loss: 0.0433 - val_accuracy: 0.9856\n","Epoch 26/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0286 - accuracy: 0.9945\n","Epoch 00026: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0286 - accuracy: 0.9945 - val_loss: 0.0435 - val_accuracy: 0.9856\n","Epoch 27/200\n","79/79 [==============================] - 90s 1s/step - loss: 0.0287 - accuracy: 0.9943 - val_loss: 0.0434 - val_accuracy: 0.9856\n","Epoch 28/200\n","79/79 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9945\n","Epoch 00028: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n","79/79 [==============================] - 91s 1s/step - loss: 0.0282 - accuracy: 0.9945 - val_loss: 0.0434 - val_accuracy: 0.9856\n","Epoch 00028: early stopping\n"],"name":"stdout"}]}]}